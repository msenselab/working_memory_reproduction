//
// This Stan program defines a logarithmic encoding model for working memory task
//
// Learn more about this model, please refer to paper
// Duration reproduction under memory pressure: Modeling the roles of visual memory load in duration encoding and reproduction
//
//    https://github.com/msenselab/working_memory_reproduction
//

// self-defined functions to calculate mean and sd of normal distribution in linear scale 
// according to mean and sd of normal distribution in log scale

functions {
real mu_normal(real mu, real variance){
  return(exp(mu+ variance *0.5));
}

real variance_normal(real mu, real variance){
  return((exp(variance)-1)*exp(2*mu + variance));
}

// self-defined function for predication
matrix predictor_rng(real[] x, int[] size, int[] gap, real ks, real ls, real ts, real kr, real sig_s2, real sigma_pr2,  real mu_pr_log, real sig_mn2, real[] par) {
vector[num_elements(x)] predY;    //predication of RP generated by model
real sig_sm2;   // sigma^2 of posterior
vector[num_elements(x)] wp_pr;    //weight of prior
vector[num_elements(x)] mu_sm;
vector[num_elements(x)] mu_post;      //mean of reproduction
vector[num_elements(x)] mu_r_log;      //mean of reproduction in logarithmic scale
vector[num_elements(x)] mu_r;      //mean of reproduction
real sig_wm2;   // sigma^2 of sensory measurement
vector[num_elements(x)] sig_r;     //sigma of RP 
vector[num_elements(x)] log_lik;

for (i in 1:num_elements(x))
{
   if(par[1] == 1){
    mu_sm[i] = log(x[i]) -ks* log(size[i]);
  }
  else{
    mu_sm[i] = log(x[i]);
  }
  
  if(par[2] == 1){
    sig_sm2 =  sig_s2 + ls*log(size[i]) + ts*log(gap[i]);  // 
  }else {
    sig_sm2 =  sig_s2 + ts*log(gap[i]);
  }
 
  wp_pr[i] = sig_sm2 /(sig_sm2 + sigma_pr2); 
  mu_post[i] = wp_pr[i]*mu_pr_log +(1-wp_pr[i]) *mu_sm[i]; 
  sig_wm2 = (sigma_pr2 *sig_sm2)/(sigma_pr2 + sig_sm2);
  if(par[3] == 1){
      mu_r_log[i] = mu_post[i] + kr*log(size[i]);
   }else{
      mu_r_log[i] = mu_post[i];
   }
   
  mu_r[i] = mu_normal(mu_r_log[i], sig_wm2);
  sig_r[i] =  sqrt(variance_normal(mu_r_log[i], sig_wm2) +sig_mn2/x[i]);
  predY[i] = normal_rng(mu_r[i], sig_r[i]); 
  log_lik[i] = normal_lpdf(predY[i]|mu_r[i], sig_r[i]);
}

return(append_col(append_col(append_col(wp_pr, mu_r), append_col(sig_r, predY)), append_col(mu_post,log_lik)));
}

}

// The input data 
data {
int<lower=0> n;
real y[n];   //measured reproductive duration 
real x[n];   //stimulus duration
int WMSize[n];        //set size in working memory task
int WMSize_new[846];    //new wm task size
int Gap[n];             //gap between production phase and reproduction phase in duration task
int Gap_new[846];       //new gap information between production phase and reproduction phase
real xnew[846];  //new target duration
real par[3]; // ks, ls, kr
}


// The parameters accepted by the model
parameters {  
//hyperparameters
real<lower=0> sig_s2;  
real<lower=0, upper = 1> ks;  // scale factor of mu_sm in production phase 
real<lower=0, upper = 1> ls;  // scale factor of sig_sm in production phase (WM load size effect)
real<lower=0, upper = 1> ts;  // scale factor of sig_sm in production phase (gap effect)
real<lower=0, upper = 1> kr;  // scale factor of mu_r in reproduction phase 
real<upper = 4> mu_pr_log;  // mean of internal prior in log scale
real<lower=0, upper =1> sig_pr2_log;  // sigma^2 of prior in log scale
real<lower=0> sig_mn2; //square of sigma of motor noise caused by WM task
} 

transformed parameters {
}

model {
real mu_sm[n];      //
real sig_sm2;   // sigma^2 of sensory measuremnet
real sig_wm2;   // sigma^2 of posterior
real mu_r_log[n];   // sigma^2 of posterior
real mu_r[n];   // sigma^2 of posterior
real wp[n];        //weight of prior
real mu_post[n];      //mean of reproduction
real sig_r[n];   // sigma^2 of posterior
real sig_wm_hat2[n]; 
ks ~ cauchy(0, 1);
ls ~ cauchy(0, 1);
kr ~ cauchy(0, 1);
ts ~ cauchy(0, 1);
mu_pr_log ~ normal(0, 1);
sig_mn2 ~ cauchy(0, 1);
sig_s2 ~ cauchy(0, 1);
sig_pr2_log ~ cauchy(0, 1);


for (i in 1:n)
{
  if(par[1] == 1){
    mu_sm[i] = log(x[i]) -ks*log(WMSize[i]);
  }
  else{
    mu_sm[i] = log(x[i]);
  }
  
  if(par[2] == 1){
   sig_sm2 =  sig_s2 + ls*log(WMSize[i])+ ts*log(Gap[i]);
  }else {
   sig_sm2 =  sig_s2 + ts*log(Gap[i]);
  }
 
  wp[i] = sig_sm2 /(sig_sm2 + sig_pr2_log); 
  mu_post[i] = wp[i]*mu_pr_log +(1-wp[i]) *mu_sm[i]; 
 sig_wm2 = sig_pr2_log *sig_sm2/(sig_pr2_log + sig_sm2);
   if(par[3] == 1){
      mu_r_log[i] = mu_post[i] + kr* log(WMSize[i]);
   }else{
      mu_r_log[i] = mu_post[i];
   }
  mu_r[i] = mu_normal(mu_r_log[i], sig_wm2);
  sig_r[i] =  sqrt(variance_normal(mu_r_log[i], sig_wm2) +sig_mn2/x[i]);
  target += normal_lpdf(y[i] | mu_r[i], sig_r[i]); 
 }
}

generated quantities {
matrix[n,6] predRP;
matrix[846,6] ynew;
vector[n] log_lik;
real log_lik_sum;
predRP = predictor_rng(x, WMSize, Gap, ks, ls, ts, kr, sig_s2, sig_pr2_log, mu_pr_log, sig_mn2, par);
ynew = predictor_rng(xnew, WMSize_new, Gap_new, ks, ls, ts, kr, sig_s2, sig_pr2_log, mu_pr_log, sig_mn2, par);
log_lik =  col(predRP, 6);
//log_lik = predictor_log_lik_rng(x, WMSize, ks, ls, kr, sig_s2, sig_pr2_log, mu_pr_log, sig_mn2, par);
log_lik_sum =  sum(log_lik);
}
